# -*- coding: utf-8 -*-
"""NFLInterceptions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lm4tcYhA5ylpNCzr626zzijoqIwOOr4C

**Testing the effect of score on NFL interception rates**

Hypothesis: Quarterbacks throw a higher rate of interceptions when their teams are trailing than winning.

Methods: Assess NFL play-by-pay data and measure how interception rates change when the scoring margin changes.
"""

import pandas as pd
import numpy as np
import os

from sqlalchemy import create_engine
from scipy import stats

import seaborn as sns

#Import data for the last 5 seasons from nflscrapR 

#Accompanying code to clean each year's data was provided by nflscrapR. Everything else is my own.

YEAR = 2019

data = pd.read_csv('https://raw.githubusercontent.com/' + \
                       'ryurko/nflscrapR-data/master/' + \
                       'play_by_play_data/regular_season/reg_pbp_' + str(YEAR) + '.csv',
                       low_memory=False)

data = data.loc[
    (data['epa'].notnull()) &
    ((data['play_type'] == 'no_play') |
    (data['play_type'] == 'pass') |
    (data['play_type'] == 'run'))
]




data.drop(data[(data['replay_or_challenge'] == 0) & (data['desc'].str.contains('Timeout'))].index, inplace=True)

data = data.loc[data.desc.str.contains('kneels|spiked') == False]

data['desc'].loc[data['play_type'] == 'no_play']

data.loc[data.desc.str.contains('left end|left tackle|left guard|up the middle|right guard|right tackle|right end|rushes'),
'play_type'] = 'run'

data.loc[data.desc.str.contains('scrambles|sacked|pass'), 'play_type'] = 'pass'

data.reset_index(drop=True, inplace=True)

#Create a smaller dataframe with plays where passer_player_name is null
passer_nan = data.loc[(data['play_type'] == 'pass') &
         (data['passer_player_name'].isnull())]
#Create a list of the indexes/indices for the plays where passer_player_name is null
passer_nan_indices = list(passer_nan.index)

data.incomplete_pass.loc[data.interception==1] = 1


for i in passer_nan_indices:
    #Split the description on the blank spaces, isolating each word
    desc = data['desc'].iloc[i].split()
    #For each word in the play description
    for j in range(0,len(desc)):
        #If a word is pass
        if desc[j] == 'pass':
            data['passer_player_name'].iloc[i] = desc[j-1]            
        else:
            pass
#Change any backwards passes that incorrectly labeled passer_player_name as Backward
data.loc[data['passer_player_name'] == 'Backward', 'passer_player_name'] == float('NaN')

data.insert(69, 'success', 0)

data.loc[data['epa'] > 0, 'success'] = 1

data.insert(70, 'Year', YEAR)

data.insert(71, 'StrYear', str(YEAR))

data.insert(72, 'PasserYearID', (data['passer_player_name']+data['StrYear']))

data.passer_player_name.loc[data.passer_player_name=='G.Minshew II'] = 'G.Minshew'

data_19 = data

#2018

YEAR = 2018

data = pd.read_csv('https://raw.githubusercontent.com/' + \
                       'ryurko/nflscrapR-data/master/' + \
                       'play_by_play_data/regular_season/reg_pbp_' + str(YEAR) + '.csv',
                       low_memory=False)

data = data.loc[
    (data['epa'].notnull()) &
    ((data['play_type'] == 'no_play') |
    (data['play_type'] == 'pass') |
    (data['play_type'] == 'run'))
]

data.incomplete_pass.loc[data.interception==1] = 1


data.drop(data[(data['replay_or_challenge'] == 0) & (data['desc'].str.contains('Timeout'))].index, inplace=True)

data = data.loc[data.desc.str.contains('kneels|spiked') == False]

data['desc'].loc[data['play_type'] == 'no_play']

data.loc[data.desc.str.contains('left end|left tackle|left guard|up the middle|right guard|right tackle|right end|rushes'),
'play_type'] = 'run'

data.loc[data.desc.str.contains('scrambles|sacked|pass'), 'play_type'] = 'pass'

data.reset_index(drop=True, inplace=True)

#Create a smaller dataframe with plays where passer_player_name is null
passer_nan = data.loc[(data['play_type'] == 'pass') &
         (data['passer_player_name'].isnull())]
#Create a list of the indexes/indices for the plays where passer_player_name is null
passer_nan_indices = list(passer_nan.index)

for i in passer_nan_indices:
    #Split the description on the blank spaces, isolating each word
    desc = data['desc'].iloc[i].split()
    #For each word in the play description
    for j in range(0,len(desc)):
        #If a word is pass
        if desc[j] == 'pass':
            data['passer_player_name'].iloc[i] = desc[j-1]            
        else:
            pass
#Change any backwards passes that incorrectly labeled passer_player_name as Backward
data.loc[data['passer_player_name'] == 'Backward', 'passer_player_name'] == float('NaN')



data.insert(69, 'success', 0)

data.loc[data['epa'] > 0, 'success'] = 1

data.insert(70, 'Year', YEAR)

data.insert(71, 'StrYear', str(YEAR))

data.insert(72, 'PasserYearID', (data['passer_player_name']+data['StrYear']))

data_18 = data

#2017

YEAR = 2017

data = pd.read_csv('https://raw.githubusercontent.com/' + \
                       'ryurko/nflscrapR-data/master/' + \
                       'play_by_play_data/regular_season/reg_pbp_' + str(YEAR) + '.csv',
                       low_memory=False)

data = data.loc[
    (data['epa'].notnull()) &
    ((data['play_type'] == 'no_play') |
    (data['play_type'] == 'pass') |
    (data['play_type'] == 'run'))
]

data.drop(data[(data['replay_or_challenge'] == 0) & (data['desc'].str.contains('Timeout'))].index, inplace=True)

data = data.loc[data.desc.str.contains('kneels|spiked') == False]

data['desc'].loc[data['play_type'] == 'no_play']

data.incomplete_pass.loc[data.interception==1] = 1


data.loc[data.desc.str.contains('left end|left tackle|left guard|up the middle|right guard|right tackle|right end|rushes'),
'play_type'] = 'run'

data.loc[data.desc.str.contains('scrambles|sacked|pass'), 'play_type'] = 'pass'

data.reset_index(drop=True, inplace=True)

#Create a smaller dataframe with plays where passer_player_name is null
passer_nan = data.loc[(data['play_type'] == 'pass') &
         (data['passer_player_name'].isnull())]
#Create a list of the indexes/indices for the plays where passer_player_name is null
passer_nan_indices = list(passer_nan.index)

for i in passer_nan_indices:
    #Split the description on the blank spaces, isolating each word
    desc = data['desc'].iloc[i].split()
    #For each word in the play description
    for j in range(0,len(desc)):
        #If a word is pass
        if desc[j] == 'pass':
            data['passer_player_name'].iloc[i] = desc[j-1]            
        else:
            pass
#Change any backwards passes that incorrectly labeled passer_player_name as Backward
data.loc[data['passer_player_name'] == 'Backward', 'passer_player_name'] == float('NaN')

data.insert(69, 'success', 0)

data.loc[data['epa'] > 0, 'success'] = 1

data.insert(70, 'Year', YEAR)

data.insert(71, 'StrYear', str(YEAR))

data.insert(72, 'PasserYearID', (data['passer_player_name']+data['StrYear']))

data_17 = data

#2016

YEAR = 2016

data = pd.read_csv('https://raw.githubusercontent.com/' + \
                       'ryurko/nflscrapR-data/master/' + \
                       'play_by_play_data/regular_season/reg_pbp_' + str(YEAR) + '.csv',
                       low_memory=False)

data = data.loc[
    (data['epa'].notnull()) &
    ((data['play_type'] == 'no_play') |
    (data['play_type'] == 'pass') |
    (data['play_type'] == 'run'))
]

data.drop(data[(data['replay_or_challenge'] == 0) & (data['desc'].str.contains('Timeout'))].index, inplace=True)

data = data.loc[data.desc.str.contains('kneels|spiked') == False]

data['desc'].loc[data['play_type'] == 'no_play']

data.loc[data.desc.str.contains('left end|left tackle|left guard|up the middle|right guard|right tackle|right end|rushes'),
'play_type'] = 'run'

data.loc[data.desc.str.contains('scrambles|sacked|pass'), 'play_type'] = 'pass'

data.reset_index(drop=True, inplace=True)

#Create a smaller dataframe with plays where passer_player_name is null
passer_nan = data.loc[(data['play_type'] == 'pass') &
         (data['passer_player_name'].isnull())]
#Create a list of the indexes/indices for the plays where passer_player_name is null
passer_nan_indices = list(passer_nan.index)

data.incomplete_pass.loc[data.interception==1] = 1


for i in passer_nan_indices:
    #Split the description on the blank spaces, isolating each word
    desc = data['desc'].iloc[i].split()
    #For each word in the play description
    for j in range(0,len(desc)):
        #If a word is pass
        if desc[j] == 'pass':
            data['passer_player_name'].iloc[i] = desc[j-1]            
        else:
            pass
#Change any backwards passes that incorrectly labeled passer_player_name as Backward
data.loc[data['passer_player_name'] == 'Backward', 'passer_player_name'] == float('NaN')

data.insert(69, 'success', 0)

data.loc[data['epa'] > 0, 'success'] = 1

data.insert(70, 'Year', YEAR)

data.insert(71, 'StrYear', str(YEAR))

data.insert(72, 'PasserYearID', (data['passer_player_name']+data['StrYear']))

data_16 = data

#2015

YEAR = 2015

data = pd.read_csv('https://raw.githubusercontent.com/' + \
                       'ryurko/nflscrapR-data/master/' + \
                       'play_by_play_data/regular_season/reg_pbp_' + str(YEAR) + '.csv',
                       low_memory=False)

data = data.loc[
    (data['epa'].notnull()) &
    ((data['play_type'] == 'no_play') |
    (data['play_type'] == 'pass') |
    (data['play_type'] == 'run'))
]

data.drop(data[(data['replay_or_challenge'] == 0) & (data['desc'].str.contains('Timeout'))].index, inplace=True)

data = data.loc[data.desc.str.contains('kneels|spiked') == False]

data['desc'].loc[data['play_type'] == 'no_play']

data.loc[data.desc.str.contains('left end|left tackle|left guard|up the middle|right guard|right tackle|right end|rushes'),
'play_type'] = 'run'

data.loc[data.desc.str.contains('scrambles|sacked|pass'), 'play_type'] = 'pass'

data.reset_index(drop=True, inplace=True)

data.incomplete_pass.loc[data.interception==1] = 1


#Create a smaller dataframe with plays where passer_player_name is null
passer_nan = data.loc[(data['play_type'] == 'pass') &
         (data['passer_player_name'].isnull())]
#Create a list of the indexes/indices for the plays where passer_player_name is null
passer_nan_indices = list(passer_nan.index)

for i in passer_nan_indices:
    #Split the description on the blank spaces, isolating each word
    desc = data['desc'].iloc[i].split()
    #For each word in the play description
    for j in range(0,len(desc)):
        #If a word is pass
        if desc[j] == 'pass':
            data['passer_player_name'].iloc[i] = desc[j-1]            
        else:
            pass
#Change any backwards passes that incorrectly labeled passer_player_name as Backward
data.loc[data['passer_player_name'] == 'Backward', 'passer_player_name'] == float('NaN')

data.insert(69, 'success', 0)

data.loc[data['epa'] > 0, 'success'] = 1

data.insert(70, 'Year', YEAR)

data.insert(71, 'StrYear', str(YEAR))

data.insert(72, 'PasserYearID', (data['passer_player_name']+data['StrYear']))

data_15 = data

#2014

YEAR = 2014

data = pd.read_csv('https://raw.githubusercontent.com/' + \
                       'ryurko/nflscrapR-data/master/' + \
                       'play_by_play_data/regular_season/reg_pbp_' + str(YEAR) + '.csv',
                       low_memory=False)

data = data.loc[
    (data['epa'].notnull()) &
    ((data['play_type'] == 'no_play') |
    (data['play_type'] == 'pass') |
    (data['play_type'] == 'run'))
]

data.drop(data[(data['replay_or_challenge'] == 0) & (data['desc'].str.contains('Timeout'))].index, inplace=True)

data = data.loc[data.desc.str.contains('kneels|spiked') == False]

data['desc'].loc[data['play_type'] == 'no_play']

data.loc[data.desc.str.contains('left end|left tackle|left guard|up the middle|right guard|right tackle|right end|rushes'),
'play_type'] = 'run'

data.loc[data.desc.str.contains('scrambles|sacked|pass'), 'play_type'] = 'pass'

data.reset_index(drop=True, inplace=True)

#Create a smaller dataframe with plays where passer_player_name is null
passer_nan = data.loc[(data['play_type'] == 'pass') &
         (data['passer_player_name'].isnull())]
#Create a list of the indexes/indices for the plays where passer_player_name is null
passer_nan_indices = list(passer_nan.index)

for i in passer_nan_indices:
    #Split the description on the blank spaces, isolating each word
    desc = data['desc'].iloc[i].split()
    #For each word in the play description
    for j in range(0,len(desc)):
        #If a word is pass
        if desc[j] == 'pass':
            data['passer_player_name'].iloc[i] = desc[j-1]            
        else:
            pass
#Change any backwards passes that incorrectly labeled passer_player_name as Backward
data.loc[data['passer_player_name'] == 'Backward', 'passer_player_name'] == float('NaN')

data.insert(69, 'success', 0)

data.loc[data['epa'] > 0, 'success'] = 1

data.insert(70, 'Year', YEAR)

data.insert(71, 'StrYear', str(YEAR))

data.insert(72, 'PasserYearID', (data['passer_player_name']+data['StrYear']))

data.incomplete_pass.loc[data.interception==1] = 1


data_14 = data

#Combining data from each season into one dataframe

df = data_14.append(data_15)

df = df.append(data_16)

df = df.append(data_17)

df = df.append(data_18)

df= df.append(data_19)

#Step One: Analyzing How League-wide interception rate changes by score

int_by_score = df.loc[(df['play_type']=='pass') & (df['pass_attempt']==1)].groupby(by='score_differential')[['interception', 'complete_pass', 'incomplete_pass', 'air_yards']].sum()

int_by_score['throw'] = int_by_score.complete_pass+int_by_score.incomplete_pass

int_by_score['INT%'] = int_by_score.interception/int_by_score.throw

int_by_score['ADOT'] = int_by_score.air_yards/int_by_score.throw


pd.set_option('display.max_rows', None) 

int_by_score

print("NFL average interception rate = " + str(int_by_score.interception.sum()/int_by_score.throw.sum()*100) + "%.")

"""Data indicate interception rate increases as deficit increases, supporting the hypothesis.

However, when teams are losing by three points or fewer, their interception rates remain below league average. The spikes back above league average when the deficit increases to 4.

Therefore, if we are to assess things in a binary fashion, rather than grouping the scenarios as "leading" or "trailing, we should do so by making the buckets "winning or within 3 points" and "losing by 4 or more."
"""

#Step Two: Analyzing Individual Quarterback Seasons

#Step 2a: Passes Thrown When Winning, Tied, or Within 3 Points (will call this group "winners")

winners = df.loc[(df['score_differential']>=-3) & (df['pass_attempt']==1)].groupby(by='PasserYearID')[['complete_pass', 'incomplete_pass', 'interception', 'yards_gained', 'sack', 'pass_attempt', 'air_yards', 'success']].sum()

winners['throws'] = winners.complete_pass + winners.incomplete_pass

winners['aDOT'] = winners.air_yards/winners.throws

winners.sort_values('throws', ascending=False)

winning_int_rate = winners['interception'].sum()/winners['throws'].sum()

winners['wINT_rate'] = winners.interception/winners.throws

winners['Completion_Rate'] = winners.complete_pass/winners.throws

winners['SR'] = winners.success/winners.pass_attempt

winners['Sack_Rate'] = winners.sack/winners.pass_attempt

winning_adot = winners['air_yards'].sum()/winners['throws'].sum()

print("For teams winning or within three points since 2014, the average interception rate is " + str(winning_int_rate*100)+ "%.")

#Step 2b: Same process but for situations when the deficit is greater than 3 points ("losers")

losers = df.loc[(df['score_differential']<-3) & (df['pass_attempt']==1)].groupby(by='PasserYearID')[['complete_pass', 'incomplete_pass', 'interception', 'yards_gained', 'sack', 'pass_attempt', 'air_yards', 'success', 'qb_dropback']].sum()

losers['throws'] = losers.complete_pass + losers.incomplete_pass

losers['aDOT'] = losers.air_yards/losers.throws


losing_int_rate = losers['interception'].sum()/losers['throws'].sum()

losing_adot = losers['air_yards'].sum()/losers['throws'].sum()

losers['lINT_rate'] = losers.interception/losers.throws

losers['SR'] = losers.success/losers.pass_attempt

losers['Sack_Rate'] = losers.sack/losers.pass_attempt

losers['Completion_Rate'] = losers.complete_pass/losers.throws



print("For teams trailing by more than 3 since 2014, the league-wide interception rate is " + str(losing_int_rate*100)+ "%.")

#Step 3: Limiting the sample to quarterbacks who threw a sufficient number of passes

#Qualified passers = those with 50 throws in a subset

qual_losers = losers.loc[losers['throws']>50]

qual_winners = winners.loc[winners['throws']>50]

ax = sns.distplot(qual_winners['wINT_rate'], bins=20)

ax = sns.distplot(qual_losers['lINT_rate'], bins=20)

"""Both rates are normally distributed.

This analysis offers more support for the hypothesis: passers that are trailing by more than 3 have higher interception rates. 

However, it is possible this bucket contains more poor players. In this case, the high interception rates could be causing the big deficits as much or more than the big deficits are causing the high interception rates.

Therefore, it will be important to limit the data to include passers who have thrown a sufficient number of passes in both buckets.
"""

#Step 4: Join sets and test significance

comb=pd.merge(qual_losers, qual_winners, on='PasserYearID')

stats.ttest_ind(comb['wINT_rate'], comb['lINT_rate'])

"""There is a significant difference between a quarterback's interception rate when his team is losing by 4 or more and winning/within 3 points."""

shape = comb.shape

print(str(shape[0]) + " quarterbacks were in our sample.")

comb['Diff'] = (comb.wINT_rate - comb.lINT_rate)

comb.Diff.mean()

#Average decline was about 0.6 percentage points.

"""Why? Hypothesis: Teams attempt riskier throws when trailing by more than 3 points."""

#Step 5: Test average depth of target (aDOT; in other words, how far down the field the quarterback throws the ball)

#aDOT is measured by dividing a passer's total air yards by his total number of throws

#Passes throw further down the field are more likely to be intercepted.

int_by_adot = df.loc[(df['play_type']=='pass') & (df['air_yards']>0) & (df['air_yards']<50) & (df['pass_attempt']==1)].groupby(by='air_yards')[['interception', 'complete_pass', 'incomplete_pass', 'air_yards']].sum()
int_by_adot['INT_Rate'] = int_by_adot.interception/(int_by_adot.complete_pass+int_by_adot.incomplete_pass)
int_by_adot['adot'] = int_by_adot.air_yards/(int_by_adot.complete_pass+int_by_adot.incomplete_pass)


sns.regplot(x="adot", y="INT_Rate", data=int_by_adot)

#aDOT significance test
stats.ttest_ind(comb['aDOT_x'], comb['aDOT_y'])

Trailing_aDOT = qual_losers['air_yards'].sum()/qual_losers['throws'].sum()

Winning_or_Close_aDOT = qual_winners['air_yards'].sum()/qual_winners['throws'].sum() 

print("Passers that are losing by more than 3 throw the ball an average of " + str(Trailing_aDOT) + " yards down the field.")
print("Passers that are winning or within 3 points throw the ball an average of " + str(Winning_or_Close_aDOT) + " yards down the field.")

graph = pd.DataFrame({'lab':['Trailing Big', 'Winning or Close'], 'val':[Trailing_aDOT, Winning_or_Close_aDOT]})
ax = graph.plot.bar(x='lab', y='val', rot=0)

"""This difference is significant.

Is this increase only a matter of increased air yards or something more?
"""

#Step 6: Test interception rates on only short throws

#The league's official stats consider short throws to be those under 15 yards.

short_winners = df.loc[(df['score_differential']>=-3) & (df['pass_attempt']==1) & (df['air_yards']<15)].groupby(by='PasserYearID')[['complete_pass', 'incomplete_pass', 'interception', 'yards_gained', 'sack', 'pass_attempt', 'air_yards', 'success']].sum()

short_winners['throws'] = short_winners.complete_pass + short_winners.incomplete_pass

short_winners['wINT_rate'] = short_winners.interception/short_winners.throws

short_losers = df.loc[(df['score_differential']<-3) & (df['pass_attempt']==1) & (df['air_yards']<15)].groupby(by='PasserYearID')[['complete_pass', 'incomplete_pass', 'interception', 'yards_gained', 'sack', 'pass_attempt', 'air_yards', 'success']].sum()

short_losers['throws'] = short_losers.complete_pass + short_losers.incomplete_pass

short_losers['lINT_rate'] = short_losers.interception/short_losers.throws

qual_short_losers = short_losers.loc[short_losers['throws']>50]

qual_short_winners = short_winners.loc[short_winners['throws']>50]

short_comb=pd.merge(qual_short_losers, qual_short_winners, on='PasserYearID')

stats.ttest_ind(short_comb['wINT_rate'], short_comb['lINT_rate'])

short_comb.interception_x.sum()/short_comb.throws_x.sum()

"""Difference is significant.

This implies that passers in addition to attempting throws further down the field, they are also taking more risks when controlling for depth of throw.
"""

#Step 7: Use these conclusions to derive score-based Expected Interception Rate.

"""This can help tell us if a quarterback's low interception rate was the product of skilled play or merely frequently playing with a lead."""

#Step 7a: Calculate 2019 INT% leaderboard

passers_2019 = df.loc[(df['pass_attempt']==1) & (df['StrYear']=='2019')].groupby(by='passer_player_name')[['complete_pass', 'incomplete_pass', 'interception', 'yards_gained', 'sack', 'pass_attempt', 'air_yards', 'success']].sum()

passers_2019['throws'] = passers_2019.complete_pass + passers_2019.incomplete_pass

passers_2019['INT_rate'] = passers_2019.interception/passers_2019.throws

qual_passers_2019 = passers_2019.loc[(passers_2019['throws']>=100)].groupby(by='passer_player_name')[['throws', 'interception', 'INT_rate']].sum()

qual_passers_2019.sort_values('INT_rate')

#Step 7b: Calculate each's quarterback's expected interception total when winning/score is close

#Expected Interception Rate: League average INT% with this score situtaion * throws

#i.e. how many interceptions would this player have thrown if he had a league-average INT% rate

winners_2019 = df.loc[(df['score_differential']>=-3) & (df['pass_attempt']==1) & (df['StrYear']=='2019')].groupby(by='passer_player_name')[['complete_pass', 'incomplete_pass', 'interception', 'yards_gained', 'sack', 'pass_attempt', 'air_yards', 'success']].sum()

winners_2019['throws'] = winners_2019.complete_pass + winners_2019.incomplete_pass

xINT_rate_w = winners_2019.interception.sum()/winners_2019.throws.sum()

winners_2019['Expected_Interceptions'] = winners_2019['throws']*xINT_rate_w

winners_2019.sort_values('Expected_Interceptions', ascending=False)

#Step 7c: Same process, but for situations when the passer is trailing by 4+



losers_2019 = df.loc[(df['score_differential']<-3) & (df['pass_attempt']==1) & (df['StrYear']=='2019')].groupby(by='passer_player_name')[['complete_pass', 'incomplete_pass', 'interception', 'yards_gained', 'sack', 'pass_attempt', 'air_yards', 'success']].sum()

losers_2019['throws'] = losers_2019.complete_pass + losers_2019.incomplete_pass

xINT_rate_l = losers_2019.interception.sum()/losers_2019.throws.sum()

losers_2019['Expected_Interceptions'] = losers_2019['throws']*xINT_rate_l

losers_2019.sort_values('Expected_Interceptions', ascending=False)

#Step 7d: Combining the two sets, to get a total expected interceptions total

comb_2019 = comb=pd.merge(winners_2019, losers_2019, on='passer_player_name')

comb_2019['Total_Throws'] = comb_2019.throws_x+comb_2019.throws_y

comb_2019['Total_Interceptions'] = comb_2019.interception_x+comb_2019.interception_y

comb_2019['Total_Expected_Interceptions'] = comb_2019.Expected_Interceptions_x+comb_2019.Expected_Interceptions_y

qual_comb_2019 = comb_2019.loc[(comb_2019['Total_Throws']>=150)].groupby(by='passer_player_name')[['Total_Throws', 'Total_Interceptions', 'Total_Expected_Interceptions']].sum()

qual_comb_2019['Diff'] = qual_comb_2019.Total_Expected_Interceptions - qual_comb_2019.Total_Interceptions

qual_comb_2019.sort_values('Diff', ascending=False)

#Step 7e: Use this data to calculate an expected interception rate and compare that to each passer's actual rate

qual_comb_2019['INT_Rate'] = qual_comb_2019.Total_Interceptions/qual_comb_2019.Total_Throws

qual_comb_2019['xINT_Rate'] = qual_comb_2019.Total_Expected_Interceptions/qual_comb_2019.Total_Throws

qual_comb_2019['Rate_Diff'] = qual_comb_2019.xINT_Rate - qual_comb_2019.INT_Rate

del qual_comb_2019['Total_Interceptions']

del qual_comb_2019['Total_Expected_Interceptions']

del qual_comb_2019['Diff']

qual_comb_2019.sort_values('Rate_Diff', ascending=False)

#Step 7f: #Standardize Both Rates

from scipy.stats import zscore

standardized = qual_comb_2019.apply(zscore)

del standardized ['Total_Throws']
del standardized ['Rate_Diff']

standardized

standardized['Diff'] = standardized.xINT_Rate - standardized.INT_Rate

standardized.sort_values('Diff', ascending=False)

"""Conclusions: 

-This analysis allows us to find insights that would otherwise not be available when looking at raw interception rates. 

-Instead of analyzing a quarterback's ability (or lack thereof) to avoid interceptions by looking at his raw interception rate, we should instead measure this skill by comparing his actual rate to his expected rate.

-A quarterback with a higher interception rate than expected can be said to have given a below average performance, but a passer with a lower raw rate than his expected mark should be viewed as above average (even if his raw mark is worse than average).

-This is because, as the data shows, when passers are trailing, they are more likely to throw interceptions, so passers on teams who frequently trail would be expected to post higher interception rates than those who frequently play from ahead.

-Example:

Consider Andy Dalton, who had a higher (i.e. worse) interception rate than league average -- 0.4 standard deviations above average. However, given the deficits his team faced, we would have expected him to post an interception rate that was much worse -- 1.6 SD higher.

Therefore, we can assess that his interception avoidance was better than an average. Decision makers at the team level should accordingly not hold his substandard raw interception rate against him, when considering the length and value of his contract, for example. 

Rather, they should actually view his ability to post a lower interception rate than what would have been expected as an asset.

Looking at his unadjusted interception total would cause stakeholders to incorrectly assume Dalton struggled with interceptions in 2019. In actuality, he was better in this regard than what we would have expected from an average quarterback, given his team so frequently trailed.
"""